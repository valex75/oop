### 1. Что такое элементарные исходы, пространство элементарных исходов, события и как они соотносятся друг с другом

Пр-во элементарных исходов **($\Omega$)** это множество, содержащее все возможные исходы данного случайного эксперимента, из которых результатом эксперимента становится ровно один элементарный исход. Случайное событие - это подмножество (всякое) пространства элементарных исходов.

Резюмируя: элементарные исходы - элементы $\Omega$, а случайное событие - подмножество $\Omega$. 

Пространство элементарных исходов называется дискретным, если число элементов (исходов) в нём конечно или счётно.

Если пространство элементарных исходов не является дискретным, то оно недискретное (ну логично), плюс если при этом наблюдаемыми результатами являются точки арифметического или координатного пространства, то оно называется непрерывным.

### 2. Интерпретация объединения двух событий
Есть случайные события A и B.
Вероятности событий соответственно P(A) и P(B).
Объединение событий - A U B (A или B или пересечение A с B)
$P(A \cup B) = P(A) + P(B) - P(AB)$
Почему минус P(AB)?
Ну, есть A = {1, 2, 3} и B = {3, 4, 5}
Тогда A U B = {1, 2, 3, 3, 4, 5}
Как видим, тройка продублировалась. Вот чтобы избежать этого клонирования исходов (и, соответственно, ошибок в расчётах), делают минус P(AB).
### 3. Интерпретация пересечения двух событий 
Есть случайные события A и B.
Вероятности событий соответственно P(A) и P(B).
$P(A \cap B) = P(A)P(B)$ - для независимых событий
$P(A \cap B) = P(A|B)P(B) = P(B|A)P(A)$ - для зависимых событий
Пересечением событий называется такой элементарный исход, который лежит и в A, и в B (т.е. событие A и событие B выполняются одновременно).

### 4. Интерпретация дополнения двух событий
A\B - дополнение события B до A: произошло A, но не произошло B
$P(A\setminus{B}) = P(A) - P(A \cap B)$

### 5. Классическое определение вероятности. Почему оно требует конечности пространства элементарных исходов
P(A) - вероятность события
N -  число элементов в пространстве элементарных исходов
k - число элементов (исходов) события A
$P(A) = \frac{k}{N}$
Если пространство имён будет бесконечно, то $P(A) = \frac{k}{\infty}$, т.е. возникает неопределённость.
### 6. Принцип сложения и пример
вероятность появления одного из двух несовместных событий, безразлично какого, равна сумме вероятностей этих событий P(A + B).
$P(A + B) = P(A) + P(B)$
Пример: найти вероятность того, что на игральной кости выпадет 1 или 2
### 7. Принцип умножения и пример
вероятность того, что два независимых события произойдут одновременно равно произведению вероятностей каждого из этих событий P(A * B)
$P(AB) = P(A)P(B)$
Пример: найти вероятность того, что на двух подкинутых монетах выпадет орёл 
### 8. Количество способов выбрать k объектов из n с возвращением и учётом порядка
Общее число различных наборов при выборе k элементов из n с возвращением и с учетом порядка равняется $n^k$

### 9. Без возвращения но с учетом порядка (размещений) 
$A_n^k = n(n-1) \cdot\space...\space\cdot (n - k + 1) = \frac{n!}{(n - k)!}$ - Число размещений из n элементов по k элементов

### 10. без возвращения и без учета порядка (сочетаний)
$C_n^k = \frac{A_n^k}{k!} = \frac{n!}{k!(n-k)!}$ - Число сочетаний из n элементов по k элементов

### 11. парадокс дней рождений (точная вероятность отсутствии коллизий)
Для 1 человека вероятность иметь уникальный др = 1 (365/365, очевидно)
Для 2 - уже 364/365 (тоже очевидно)
для n-го человека будет справедлива формула $P(\text{нет коллизий}) = \frac{365-(n-1)}{365}$
Ну а вероятность уникальности дней рождений у всех людей в коллектива равна:
$P(\text{нет коллизий}) = \frac{365}{365} \cdot \frac{364}{365} \cdot \frac{363}{365} \cdots \frac{365 - (n - 1)}{365}$
Или если упрощать:
$P(\text{нет коллизий}) = \frac{365!}{(365 - n)! \cdot 365^n}$
### 12. парадокс дней рождений (верхняя оценка вероятностей отсутствии коллизий)
Аппроксимируя $P(\text{нет коллизий}) = \frac{365!}{(365 - n)! \cdot 365^n}$ (раскладываем экспоненту в ряд Тейлора) получаем: $e^\frac{-n^2}{2\cdot365}$
### 13. что такое достоверное событие
$P(A) = 1$
### 14. что такое невозможное событие
$P(A) = 0$
### 15. Общее определение вероятностной меры
$P$ - вероятностная мера $\Omega$ если:
1) Для любого $A \subseteq \Omega, P(A) \geq 0$
2) $P(\Omega) = 1$
3) Для попарно несовместных событий $P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)$
### 16. Попарно несовместные события
События называются попарно несовместными, если для событий $A_1, A_2, ..., A_n \subseteq \Omega$ выполняется условие: $A_i \cap A_j = \emptyset$ при всех $i \neq j$
### 17. Определение независимости для двух событий
События называются независимыми если $P(AB) = P(A)P(B)$
### 18. Определение независимости для совокупности
События $A_1, A_2, ..., A_n$ называются независимыми в совокупности, если для любого подмножества индексов $\{i_1, i_2, ..., i_k\} \subset \{1, 2, ..., n\}$, $2 \leq k \leq n$, выполняется $P(A_{i_1}, A_{i_2}, ..., A_{i_k}) = P(A_{i_1})P(A_{i_2})...P(A_{i_k})$.
### 19. Определение условной вероятности
Условная вероятность - вероятность наступления события A при условии, что событие B произошло:
$P(A|B) = \frac{P(AB)}{P(B)}$
### 20. Определение полной группы событий (гипотез)
Существует некий набор событий (в контексте определения формулы полной вероятности этот набор событий называется вспомогательным, а каждое событие принято называть гипотезой) $H_1, H_2, ..., H_n$, которые удовлетворяют следующим требованиям:
1) Гипотезы попарно несовместны ($H_iH_j = \emptyset (i \neq j)$)
2) $A \subset \bigcup_{i=1}^{n}H_i$

### 21. Формула полной вероятности
Пусть нас интересует вероятность события $A$ и, предположим, что наряду с $A$ существует набор вспомогательных событий $H_1, H_2, ..., H_i$, который является полной группой событий. Тогда справедлива формула полной вероятности:
$P(A) = \sum_{i=1}^n P(A|H_i)P(H_i)$

### 22.  Формула Байеса
Пусть $H_1, H_2, ..., H_n$ - полная группа событий, и $A$ - некоторое событие с положительной вероятностью. Тогда условная вероятность события $H_k$ при условии, что в результате эксперимента наблюдалось событие $A$, может быть вычислена по формуле:
$P(H_k|A) = \frac{P(H_k)P(A|H_k)}{\sum_{i=1}^{n}P(H_i)P(A|H_i)} = \frac{P(H_k)P(A|H_k)}{P(A)}$

### 23. Априорная и апостериорная вероятности
Вероятности гипотез $P(H_1), P(H_2), ...$ (до того, как событие $A$ имело место) называют априорными
Вероятности гипотез при случившемся событии $A$ (т.е. $P(H_1|A), P(H_2|A), ...$) называют апостериорными
### 24. Шансы, связь с вероятностью
$\text{Шансы в пользу события } A = \frac{m}{n - m}$
$\text{Вероятность (каждое событие равновероятно) в пользу события A} = \frac{m}{n}$
m - число благоприятных исходов
n - общее число исходов
**Из вероятности в шансы**: Если $P(A) = p$, то шансы в пользу события $A$ можно выразить как: $\text{Шансы}(A) = \frac{p}{1 - p}$
**Из шансов в вероятность**: Если шансы в пользу события $A$ равны $\frac{m}{n}$, то вероятность события $A$ может быть выражена как: $P(A) = \frac{m}{m + n}$
### 25. True Positive, False Positive, True Negative, False Negative
True Positive - Предсказание того, что событие A произошло при условии того, что событие A действительно произошло
False Positive - Предсказание того, что событие A произошло при условии того, что событие A при этом не произошло
True Negative - Предсказание того, что событие A не произошло при условии того, что событие A действительно не произошло
False Negative - Предсказание того, что событие A не произошло при условии того, что событие A при этом произошло
### 26. Точность
Точность — это доля правильных предсказаний (как положительных, так и отрицательных) среди всех предсказаний.
$\text{Точность} = \frac{TP + TN}{TP + TN + FP + FN}$
### 27. Чувствительность
Чувствительность (или полнота) — это доля правильно предсказанных положительных случаев среди всех фактических положительных случаев.
$\text{Чувствительность} = \frac{TP}{TP + FN}$
### 28. Специфичность
Специфичность — это доля правильно предсказанных отрицательных случаев среди всех фактических отрицательных случаев.
$\text{Специфичность} = \frac{TN}{TN + FP}$
### 29. Коэффициент Байеса и его связь с чувствительностью и специфичностью
Коэф Байеса - $\frac{P(A|H)}{P(A|\overline{H})}$
Обновление шансов гипотезы $H$ по формуле Байеса производится простым умножением на коэффициент Байеса.
Сам коэффициент определяется следующим образом:
$\frac{P(A|H)}{P(A|\overline{H})} = \frac{чувствительность}{1 - специфичность}$

### 30. Типы данных (количественные/качественные, целые/непрерывные, номинальные/порядковые)
**Количественные данные** (или числовые данные) представляют собой значения, которые можно измерить и выразить в числовом формате. Они делятся на два подтипа:
    - **Целые числа**: данные, которые принимают только целые значения (например, количество людей, количество товаров).
    - **Непрерывные числа**: данные, которые могут принимать любые значения в определенном диапазоне (например, рост, вес, температура).
**Качественные данные** (или категориальные данные) представляют собой описательные значения, которые не могут быть измерены численно. Они также делятся на два подтипа:
    - **Номинальные данные**: данные, которые представляют собой категории без какого-либо порядка (например, цвет глаз, пол, национальность).
    - **Порядковые данные**: данные, которые представляют собой категории с естественным порядком или ранжированием, но без фиксированного интервала между значениями (например, уровень образования, степень удовлетворенности).
**Целые данные** (или дискретные данные) представляют собой данные, которые могут принимать только определенные значения, часто целые числа. Они не могут принимать дробные значения (например, количество студентов в классе, количество автомобилей). **Непрерывные данные** представляют собой данные, которые могут принимать любое значение в заданном диапазоне. Они могут быть дробными и включать такие величины, как температура, время и расстояние.
**Номинальные данные**: это категории, которые не имеют внутреннего порядка. Примеры включают:
    - Цвет (красный, зеленый, синий)
    - Тип животного (собака, кошка, птица)
**Порядковые данные**: это категории, которые имеют определенный порядок, но расстояние между категориями не обязательно равно (например):
    - Уровень образования (начальное, среднее, высшее)
    - Оценки (плохо, удовлетворительно, хорошо, отлично)
### 31. Эмпирическая функция распределения
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
Эмпирическая функция распределения - один из способов визуализации распределения значений выборки
$F_n^* (t) = \frac{1}{n}\sum_{k=1}^{n}I\{X_k < t\}$ 
где $I\{X_k < t\}$ равен единице или нулю в зависимости от того верно или не верно указанное в скобках условие (в данном случае $I\{X_k < t\} = 1 \text{ если } X_k < t \text{ верно}, \text{ иначе } 0$)
### 32. Выборочная квантиль
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
Выборочная квантиль — это статистическая мера, которая делит упорядоченный набор данных на равные части. Квантили позволяют оценить распределение данных и понять, как они распределены относительно медианы и других значений.
$Q_{(p)} = x_{(p(n + 1))}$, где $p$ - это доля выборки, $n$ - количество элементов в выборке, $x$ - число, по которому осуществляется выборка/ В случае, если $p(n + 1)$ - дробное число, интерполяция по следующей формуле: $x_n + p(n + 1) * (x_{(n + 1)} - x_n)$
### 33. Выборочное среднее
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
$\overline{X}:=\frac{1}{n}\sum_{k=1}^{n}X_k$
### 34. Геометрическое среднее
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
$\sqrt[n]{\prod_{k=1}^{n}X_k}$
### 35. Гармоническое среднее
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
$\frac{n}{\sum_{k=1}^{n}\frac{1}{X_k}}$
### 36. Медиана для выборки
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
$\widehat{\mu}:=X_{([(n+1)/2])}$ - для нечетного числа элементов в выборке
$\widehat{\mu}:= \frac{X_{([n/2])} + X_{([(n+1)/2])}}{2}$ - для четного числа элементов в выборке
### 37. Выборочная дисперсия
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
$S^2 := \frac{1}{n}\sum_{k=1}^{n}(X_k-\overline{X})^2$
### 38. Стандартное отклонение
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
$S := \sqrt{\frac{1}{n}\sum_{k=1}^{n}(X_k-\overline{X})^2}$
### 39. Размах
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
$X_{(n)}-X_{(1)}$
### 40. Межквартильный размах
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
$X_{([3n/4])}-X_{([n/4])}$
### 41. Как строится бустрап выборка из данной выборки
$X_1, X_2, X_3, ..., X_n$ - выборка
Вариационный ряд выборки $X_1, X_2, X_3, ..., X_n$ - пос-ть её элементов, расположенная по возрастанию ($X_{(1)} \leq X_{(2)} \leq ... \leq X_{(n)}$)
Бутстрап — это вычислительный метод статистики, основанный на принципе повторной выборки с возвращением из исходного набора данных для оценки распределения статистики интереса.
Алгоритм работы метода следующий:
1. Из генеральной совокупности формируется случайная выборка из $N(t)$ наблюдений (например, если требуется определить среднюю сумму чека посетителя супермаркета, будем оценивать ее на основе выборки из 1 000 клиентов).
2. К выборке применяется случайная перевыборка с возвратом (псевдовыборка) того же объема, но в которую некоторые наблюдения могут попасть несколько раз, а другие не попасть совсем. Например, если выборка содержала 5 значений (1, 2, 3, 4, 5), то результатом перевыборки может быть (2, 2, 4, 5, 5). Затем вычисляется ее среднее.
3. Процедура перевыборки повторяется достаточно много раз (несколько десятков, сотен или даже тысяч), и для каждого случая вычисляется интересующая нас статистика.
4. Полученные значения статистики образуют новую выборку, которая и называется бутстрап выборкой.
Т.е. пусть $X_1^*, X_2^*, ..., X_n^*$ - случайная выборка из $X_1, X_2, X_3, ..., X_n$ с повторениями.
Далее делаем следующее:
(потом допишу)

Доверительный интервал бутстрапа уровня $1-\varepsilon$:
$$\LARGE(\widehat{\theta}_{\frac{\varepsilon}{2}}^*,\widehat{\theta}_{1-\frac{\varepsilon}{2}}^*)$$
### 42. Формула вероятности получения k успехов из n испытаний Бернулли
Формула для вероятности получения $k$ успехов из $n$ испытаний Бернулли описывается с помощью биномиального распределения. В этом случае мы рассматриваем последовательность из $n$ независимых испытаний, каждое из которых может закончиться успехом (с вероятностью $p$) или неудачей (с вероятностью $1 - p$).
$P(X = k) = C_n^k \cdot p^k(1-p)^{n-k}$
Где:
- $P(X = k)$ — вероятность того, что из $n$ испытаний будет ровно $k$ успехов.
- $C_n^k = \frac{n!}{k!(n-k)!}$ — (количество сочетаний) биномиальный коэффициент, который представляет собой количество способов выбрать $k$ успехов из $n$ испытаний.
-  $p^k$ — вероятность того, что $k$ испытаний завершились успехом.
- $(1 - p)^{n - k}$  — вероятность того, что оставшиеся $n - k$ испытаний завершились неудачами.
### 43. Формула вероятности первому успеху произойти на k-ом испытании
Формула вероятности того, что первый успех произойдет на $k$-ом испытании, относится к геометрическому распределению. В этой ситуации мы рассматриваем последовательность независимых испытаний, каждое из которых имеет два возможных исхода: успех (с вероятностью $p$) и неудача (с вероятностью $1 - p$).
$P(X = k) = (1 - p)^{k-1} \cdot p$
### 44. Математическое ожидание для дискретных случайных величин
Если $X$ — дискретная случайная величина, принимающая значения $x_1, x_2, \ldots, x_n$ с вероятностями $P(X = x_i) = p_i$, то математическое ожидание $E(X)$ вычисляется по формуле: 
$E(X) = \sum_{i=1}^{n} x_i \cdot p_i$
### 45.  Распределение Бернулли: ряд/таблица распределения
Функция вероятности для распределения Бернулли может быть записана следующим образом:

$P(X = x) = \begin{cases} p & \text{если } x = 1 \\1 - p & \text{если } x = 0 \end{cases}$

где $X$ — это случайная величина, принимающая значения 0 и 1.
### 46. Биномиальное распределение: ряд/таблица распределения
Биномиальное распределение описывает количество успехов в фиксированном числе независимых испытаний, каждое из которых имеет два возможных исхода (успех и неудача). Это распределение определяется двумя параметрами:
$n$: общее количество испытаний (например, количество бросков монеты).
$p$: вероятность успеха в каждом испытании.

Функция вероятности:
$P(X = k) = C_n^k \cdot p^k(1-p)^{n-k}$
### 47. Геометрическое распределение: ряд/таблица распределения
Геометрическое распределение описывает количество испытаний до первого успеха в серии независимых испытаний, каждое из которых имеет два возможных исхода (успех и неудача). Это распределение определяется одним параметром:
$p$: вероятность успеха в каждом испытании.

Функция вероятности:
$P(X = k) = (1 - p)^{k - 1} p$
### 48. Распределение Пуассона: ряд/таблица распределения
Распределение Пуассона описывает вероятность того, что в фиксированном интервале времени или пространства произойдет определенное количество событий, при условии, что события происходят с известной средней скоростью и независимо друг от друга. Это распределение определяется одним параметром:
$\lambda$: среднее количество событий, происходящих в заданном интервале (интенсивность).

Функция распределения:
$P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}$

### 49. Теорема о приближении Пуассона: формулировки
Пусть $n \rightarrow \infty$ и $p_n = \frac{\lambda}{n}$, $\lambda > 0$
и пусть $X_1, ..., X_n$ - пос-ть случайных величин, распределенных биномиально.
Тогда $P(X_n = k) = C_n^k \cdot p^k \cdot (1-p)^{n-k} \rightarrow_{n \rightarrow \infty} \frac{\lambda}{k!}\cdot e^{-\lambda}$
Более того, если $Z$ распределен по Пуассону, то для всякого $A$ $|P(X_n \in A) - P(Z \in A)| < np^2$ - Уточнённая теорема Пуассона
### 50. Какое распределение имеет сумма конечного числа независимых Бернуллиевских случайных величин?
Пусть $X_1, X_2, \ldots, X_n$ — независимые Бернуллиевские случайные величины с параметром $p$, то есть: $X_i \sim \text{Bernoulli}(p) \quad (i = 1, 2, \ldots, n)$
Тогда сумма этих случайных величин: $S_n = X_1 + X_2 + \ldots + X_n$ имеет биномиальное распределение.
Вероятность того, что сумма $S_n$ равна $k$ (где $k$ — количество успехов) выражается формулой: $P(S_n = k) = \binom{n}{k} p^k (1 - p)^{n - k} \quad (k = 0, 1, \ldots, n)$ где $\binom{n}{k}$ — биномиальный коэффициент, равный количеству способов выбрать $k$ успехов из $n$ испытаний.
### 51. Какое распределение имеет сумма конечного числа независимых Пуассоновских случайных величин?
Пусть $X_1, X_2, \ldots, X_n$ — независимые Пуассоновские случайные величины с параметрами $\lambda_1, \lambda_2, \ldots, \lambda_n$, соответственно. Тогда сумма этих случайных величин: $S_n = X_1 + X_2 + \ldots + X_n$ имеет также Пуассоновское распределение.

Интуитивно это можно понять следующим образом: если каждый из процессов (каждая пуассоновская случайная величина) описывает количество событий, происходящих в определённый интервал, то сумма этих процессов будет описывать общее количество событий, которые произошли в том же интервале, что и в каждом из процессов. Поскольку события происходят независимо, общее количество событий также будет следовать распределению Пуассона с параметром, равным сумме параметров отдельных процессов.

Сумма $S_n$ распределена по закону Пуассона с параметром, равным сумме параметров отдельных случайных величин:
$S_n \sim \text{Poisson}(\lambda_1 + \lambda_2 + \ldots + \lambda_n)$

Вероятность того, что сумма $S_n$ равна $k$ (количество событий) выражается формулой:
$P(S_n = k) = \frac{(\lambda_1 + \lambda_2 + \ldots + \lambda_n)^k e^{-(\lambda_1 + \lambda_2 + \ldots + \lambda_n)}}{k!} \quad (k = 0, 1, 2, \ldots)$
### 52. Что такое схема Бернулли и как она связана со следующими распределениями: Бернулли, биномиальное, геометрическое, Пуассона?
Схема Бернулли описывает серию простых (и независимых друг от друга) экспериментов, у каждого из которых может быть лишь 2 возможных исхода. Эти исходы принято называть успехом и неудачей. Также обычно вероятность успеха обозначают через $p$, а вероятность неудачи $q = 1 − p$.

Распределение Бернулли имеет случайная величина, показывающая результат одного из $n$ экспериментов
Биномиальное распределение имеет случайная величина, показывающая число успехов $k$ из череды $n$ испытаний
Геометрическое распределение имеет случайная величина, показывающая вероятность первого успеха с череде $n$ испытаний
Распределение Пуассона (по теореме о приближении Пуассона) будет иметь случайная величина, показывающая, как и в случае с биномиальным распределением, чисто успехов $k$ из череды $n$ испытаний, при том условии, что $n \rightarrow \infty$ и $p_n = \frac{\lambda}{n}$, $\lambda > 0$
### 53. Как задаётся совместно распределение двух дискретных случайных величин?
Говорят, что задано совместное распределение двух дискретных случайных величин, измеряемых в одном и том же случайном эксперименте, если для каждой пары значений этих величин $(x_i, y_j)$ задана вероятность $P(X = x_i, Y = y_j) = p_{ij}$, где $x_i, i = 1, ..., n$ - множество возможных значений $X$, а $y_j, j = 1, ..., m$ - множество всех возможных значений $Y$.
### 54. Генерация дискретных распределений на основе равномерно выбранной точки в отрезке [0; 1].
Генерим точку:
1) $x  \backsim uniform[0; 2^n-1]$
2) $Y = \frac{x}{2^n-1}$ - равномерное распределение на отрезке [0; 1]
*Далее для конкретных распределений:*
*Бернулли - если Y < p, то 0, иначе - 1*
*Биномиальное - Ищем количество успехов $k$, такое что $P(X \leq k) \geq Y$, для этого юзаем кумулятивную функцию распределения $P(X≤k)=\sum_{i=0}^{k}​C_{i}^{n}p^i(1−p)^{n−i}$, $C_i^n = \frac{n!}{i!(n-i)!}$* 
*Ну и далее перебираем $k$ от 1 до $n$*
...
### 55. Разница между случайной величиной и распределением. Привести примеры обоих и того, как они связаны друг с другом
Случайная величина - численное выражение результата случайного события. Пример: количество попавших пуль в мишень, затраченное время на решение задачи и т.п.
Распределение описывает область значений случайной величины и соответствующие этим значениям вероятности. Пример: вероятность того, что в цель попала конкретная пронумерованная пуля (пусть пуль было 100) $P(X = x) = 1/100, 1 \leq x \leq 100; P(X = x) = 0, otherwise$ 
Каждая случайная величина имеет распределение, показывающее связь вероятности с её значениями, зная распределение случайной величины, можно вычислить вероятности событий, связанных с этой величиной.
Пример связи: бросание игральной кости. Случайная величина - результат броска кости, распределение - вероятность выпадения каждой грани кости. Связь в том, что каждому $x_i \in X$ соответствует свой $p_i \in P(X)$.  
### 56. Определение независимости абсолютно непрерывных случайных величин через плотности
Плотность распределения - любая такая функция $f(t)$, что:
1) ф-я $f$ неотрицательна
2) ф-я $f$ нормированна ($\int_{-\infty}^{+\infty}f(s)ds = 1$)
Плотность полностью задаёт распределение случайной величины: если $f_k(t$) - плотность $k$, то для любого множества $A \subseteq R$: 
$P(A) = \int_Af_k(s)ds$
Т.е. плотности задают не вероятности отдельных значений, а вероятности
принять значения из какого-то множества. Определение похоже на геометрическую вероятность, поэтому справедливо будет сказать, что абсолютно непрерывные случайные величины $X$ и $Y$ независимы, если их совместная плотность будет равна произведению их плотностей по отдельности или:
$f_{X,Y}(x,y) = f_X(x) \cdot f_Y(y)$
### 57. Определение независимости случайных величин через функции распределения
Определение функции распределения для дискретных случ. величин и непрерывных случ. величин одинаковое, т.е. для случайной величины k ф-я распределения будет выглядеть как:
$F_k(t) = P(k < t)$
В случае с непрерывной случайной величиной она оказывается связана с плотностью распределения этой случайной величины. Связь следующая:
$F_k(t) = P(k \in (-\infty;t)) = \int_{-\infty}^{t}f_k(s)ds, f_k(t)=F_k^{'}(t)$
Случайные величины $X$ и $Y$ независимы если их совместная ф-я распределения будет равна произведению их ф-й распределения по отдельности или:
$F_{X,Y}(x,y) = F_X(x) \cdot F_Y(y)$
где $F_{X,Y}(x,y) = P(X \leq x, Y \leq y)$
### 58. Формула свёртки для суммы двух абсолютно непрерывных распределений
Свертка позволяет найти плотность суммы двух непрерывных случайных величин (пусть это будут $x$ и $y$):
$f_{x+y}(t) = \int_{-\infty}^{+\infty} f_x(s)f_y(t-s)ds = \int_{-\infty}^{+\infty} f_x(t-s)f_y(s)ds$
### 59. Математическое ожидание для абсолютно непрерывных случайных величин
Для абсолютно непрерывной случайной величины $X$ с плотностью $f_X(x)$
математическое ожидание определяется следующим образом:
$E[X] = \int_{R}x \cdot f_X(s)ds$
Матожидание существует только если приведённый интеграл сходится
### 60. Формула для нахождения плотности линейного преобразования абсолютно непрерывной случайной величины
Линейное преобразование абс.непрерывной случайной величины: $Y = aX + b$, плотность вероятности этой величины: $f_Y(y) = \frac{1}{|a|}f_X(\frac{y-b}{a})$, где $X = \frac{Y - b}{a}$
### 61. Определение квантили для случая строго возрастающей функции распределения, общее определение квантили
Квантиль порядка $p$ - числовая характеристика закона распределения случайной величины; такое число, что данная случайная величина попадает левее его с вероятностью, не превосходящей $\eta$, обозначается как 
$x_p = inf\{t ∶ p < F(t)\} = sup\{t ∶ p ⩾ F(t)\}$ что эквивалентно $P(x < x_p) \leq p$ и $P(x > x_p) \leq 1-p$

Для строго возрастающей функции существует единственный квантиль $x_p$ любого порядка $p \in (0, 1)$, который однозначно определяется из уравнения $F(x_p) = p$, и, следовательно, $x_p = F^{-1}(p)$
### 62. Что такое медиана для дискретного распределения? 
Медиана для дискретного распределения $m$ - это мера, делящая распределение на две равные части.
$F(m) = 0.5$ 
или
$F(m) = P(X \leq m) = \sum_{x \leq m}p(x) \geq 0.5$
### 63. Распределение, равномерное на отрезке: плотность и функция распределения
Равномерное распределение на отрезке $[a,b]$, где $a < b$ описывает случайную величину $X$, которая принимает значения на этом отрезке с одинаковой вероятностью.
$X \sim U(a, b)$
Плотность вероятности:
$f(x) = \begin{cases} \frac{1}{b-a}, \mbox{ если } a \leq x \leq b \\ 0,\mbox{ иначе} \end{cases}$
Функция распределения:
$F(x) = \begin{cases} 0, \mbox{ если } x < a \\ \frac{x-a}{b-a}, \mbox{ если } a \leq x < b \\ 1, \mbox{ если } x \geq b \end{cases}$
### 64. Экспоненциальное (или показательное) распределение: плотность и функция распределения
В прикладных задачах чаще всего служит для описания времени, прошедшего до наступления определенного события
$X \sim Exp(\lambda)$
Плотность распределения:
$f(x) = \begin{cases} \lambda e^{-\lambda x}, & \text{если } x \geq 0 \\ 0, & \text{иначе} \end{cases}$
Функция распределения:
$F(x) = \begin{cases} 0, & \text{если } x < 0 \\ 1 - e^{-\lambda x}, & \text{если } x \geq 0 \end{cases}$
### 65. Нормальное распределение: плотность и функция распределения
Случайная величина $X$ имеет нормальное распределение с параметрами $\mu$ и $\sigma^2$, если её плотность вероятности $f(x)$ задаётся следующим образом:
$X \sim N(\mu, \sigma^2)$ 
где: 
$\mu$ — математическое ожидание (среднее значение) распределения. 
$\sigma^2$ — дисперсия распределения (вариация значений вокруг среднего).

Плотность вероятности $f(x)$ нормального распределения определяется следующей формулой: $$ f(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x - \mu)^2}{2\sigma^2}} $$
Функция распределения $F(x)$ для нормального распределения описывает вероятность того, что случайная величина $X$ примет значение меньше или равно $x$. Она определяется как: $$ F(x) = P(X \leq x) = \int_{-\infty}^{x} f(t) , dt $$ Где $f(t)$ — плотность вероятности, заданная выше.
### 66. Стандартное нормальное распределение: плотность и функция распределения
Для упрощения расчетов часто используется стандартное нормальное распределение, которое имеет параметры $\mu = 0$ и $\sigma = 1$. Обозначается как: $$ Z \sim N(0, 1) $$ Плотность вероятности стандартного нормального распределения: $$f(z) = \frac{1}{\sqrt{2\pi}} e^{-\frac{z^2}{2}}$$ Чтобы преобразовать любое нормальное распределение в стандартное, используется следующая формула: $$Z = \frac{X - \mu}{\sigma}$$ где $Z$ — стандартизированная случайная величина, а $X$ — исходная случайная величина.
### 67. Определение сходимости последовательности случайных величин по вероятности
**Сходимость по вероятности** — это один из типов сходимости последовательностей случайных величин, который описывает, как последовательность случайных величин ведет себя по мере увеличения индекса.
Последовательность случайных величин $X_n$ сходится к случайной величине $X$ по вероятности, если для любого $\epsilon > 0$ выполняется следующее условие:

$$ \lim_{n \to \infty} P(|X_n - X| > \epsilon) = 0. $$
- **$P(|X_n - X| > \epsilon)$**: Это вероятность того, что абсолютное отклонение случайной величины $X_n$ от $X$ превышает некоторую положительную величину $\epsilon$.
- **$\lim_{n \to \infty}$**: Указывает на то, что мы рассматриваем поведение последовательности по мере увеличения $n$.
- **$= 0$**: Условие, что вероятность отклонения стремится к нулю, означает, что с увеличением $n$ значения $X_n$ становятся все ближе к $X$ с высокой вероятностью.
### 68. Формулировка закона больших чисел
Слабый закон больших чисел - Если $X_1, X_2, \ldots, X_n$ — независимые и одинаково распределенные случайные величины с математическим ожиданием $E[X_i] = \mu$ и конечной дисперсией $Var(X_i) = \sigma^2 < \infty$, то для выборочного среднего $\bar{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i$ выполняется:

$$ \lim_{n \to \infty} P\left( |\bar{X}_n - \mu| > \epsilon \right) = 0 \quad \text{для любого } \epsilon > 0. $$

Сильный закон больших чисел утверждает, что при тех же условиях, что и в слабом законе, выборочное среднее $\bar{X}_n$ сходится почти наверное к математическому ожиданию $\mu$:

$$ P\left( \lim_{n \to \infty} \bar{X}_n = \mu \right) = 1. $$
### 69. Формулировка ЦПТ
Пусть $X_1, X_2, \ldots, X_n$ — независимые и одинаково распределенные случайные величины с конечным математическим ожиданием $E[X_i] = \mu$ и конечной дисперсией $Var(X_i) = \sigma^2 > 0$. Обозначим выборочное среднее как:

$$ \bar{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i. $$

Тогда, при $n \to \infty$, распределение стандартизированной выборочной суммы:

$$ Z_n = \frac{\bar{X}_n - \mu n}{\sigma\sqrt{n}} $$

сходится по распределению к стандартному нормальному распределению $N(0, 1)$:

$$ Z_n \xrightarrow{d} N(0, 1). $$
Или
$$ P(X_n \in A) -> P(Y \in A) $$
где $Y \sim N_{0,1}$ 

Центральная предельная теорема утверждает, что независимо от исходного распределения случайных величин, их сумма (или среднее) будет стремиться к нормальному распределению, если количество слагаемых достаточно велико. Это означает, что нормальное распределение является "пределом" для распределений сумм независимых случайных величин.
### 70. Что такое стандартизация случайной величины
Для случайной величины $X$ с математическим ожиданием $E[X] = \mu$ и дисперсией $Var(X) = \sigma^2 > 0$, стандартизация осуществляется по следующей формуле:

$$ Z = \frac{X - \mu}{\sigma}, $$

где:

- $Z$ — стандартизированная случайная величина (или Z-оценка);
- $X$ — исходная случайная величина;
- $\mu$ — математическое ожидание $X$;
- $\sigma$ — стандартное отклонение $X$, равное $\sqrt{Var(X)}$.
Стандартизация позволяет преобразовать значения случайной величины $X$ так, что:

- Новый случайный процесс $Z$ имеет среднее значение $E[Z] = 0$, что означает, что он центрирован вокруг нуля.
- Новый случайный процесс $Z$ имеет дисперсию $Var(Z) = 1$, что означает, что его разброс относительно среднего значения нормализован.

Таким образом, стандартизация помогает нам понять, насколько сильно значение случайной величины отклоняется от ее среднего значения в терминах стандартных отклонений. Например, если $Z = 2$, это означает, что значение $X$ находится на два стандартных отклонения выше своего среднего.
### 71. Определения ковариации и корреляции
**Ковариация** — это статистическая мера, которая показывает, как две случайные величины изменяются вместе. Она позволяет оценить направление и степень линейной зависимости между этими величинами.
Для двух случайных величин $X$ и $Y$ с математическими ожиданиями $E[X] = \mu_X$ и $E[Y] = \mu_Y$ **ковариация** определяется как:

$$ Cov(X, Y) = E\left[(X - \mu_X)(Y - \mu_Y)\right]. $$
**Корреляция** — это стандартная мера, которая также показывает степень и направление линейной зависимости между двумя случайными величинами, но в отличие от ковариации, корреляция нормализована и принимает значения в диапазоне от -1 до 1.
Корреляция между случайными величинами $X$ и $Y$ определяется как:

$$ \rho_{X,Y} = \frac{Cov(X, Y)}{\sigma_X \sigma_Y}, $$

где:

- $\rho_{X,Y}$ — коэффициент корреляции между $X$ и $Y$;
- $Cov(X, Y)$ — ковариация между $X$ и $Y$;
- $\sigma_X$ и $\sigma_Y$ — стандартные отклонения случайных величин $X$ и $Y$, соответственно.
### 72. Дисперсия: обе формулы
**Дисперсия** — это статистическая мера, которая количественно оценивает, насколько значения случайной величины отклоняются от их среднего (математического ожидания). Она показывает, насколько разбросаны значения случайной величины относительно её математического ожидания.
**Формула через математическое ожидание**:
$$Var(X) = E[(X - \mu)^2] = E[X^2] - (E[X])^2.$$
Здесь:
$E[X^2]$ — это математическое ожидание квадрата случайной величины $X$.
$(E[X])^2$ — это квадрат математического ожидания $X$.
**Выборочная дисперсия**:
Если у нас есть выборка из $n$ наблюдений $X_1, X_2, \ldots, X_n$, то выборочная дисперсия определяется как:
$$S^2 = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2,$$
где:
$\bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i$ — выборочное среднее.
### 73. Правило трёх сигм
Если случайная величина $X$ имеет нормальное распределение с математическим ожиданием $\mu$ и стандартным отклонением $\sigma$, то:
- Около 68% значений $X$ находятся в диапазоне от $\mu - \sigma$ до $\mu + \sigma$.
- Около 95% значений $X$ находятся в диапазоне от $\mu - 2\sigma$ до $\mu + 2\sigma$.
- Около 99.7% значений $X$ находятся в диапазоне от $\mu - 3\sigma$ до $\mu + 3\sigma$.
### 74. Состоятельность оценки
Состоятельность оценки — это свойство статистической оценки, которое означает, что по мере увеличения объема выборки оценка будет стремиться к истинному значению параметра, который она оценивает. То есть, если мы будем брать все больше и больше наблюдений, то наша оценка будет становиться все более точной и близкой к реальному значению. 
Формально, оценка считается состоятельной, если для любого ε > 0 вероятность того, что абсолютная ошибка оценки меньше ε, стремится к 1 при увеличении объема выборки. Это свойство важно, так как оно гарантирует, что с увеличением данных мы можем ожидать более надежные и точные результаты. 
Примером состоятельной оценки может служить выборочное среднее: по мере увеличения числа наблюдений выборочное среднее будет стремиться к истинному среднему значению генеральной совокупности. 
Пусть у нас есть выборка $X_1, X_2, \ldots, X_n$, которая является независимой и одинаково распределенной $i.i.d.$ выборкой из некоторой генеральной совокупности с истинным параметром $\theta$. Мы хотим оценить этот параметр с помощью некоторой оценки $\hat{\theta}_n$, которая зависит от объема выборки $n$. Оценка $\hat{\theta}_n$ считается состоятельной, если: $\hat{\theta}_n \xrightarrow{P} \theta \quad \text{(в вероятности)}$ 
Это означает, что для любого $\epsilon > 0$:
$\lim_{n \to \infty} P(|\hat{\theta}_n - \theta| < \epsilon) = 1$
### 75. Несмещенность оценки
Несмещенность оценки — это свойство статистической оценки, которое означает, что среднее значение этой оценки, рассчитанное по всем возможным выборкам, равно истинному значению параметра, который она оценивает. То есть, если мы будем многократно проводить эксперименты и вычислять оценку, то в среднем она будет давать правильный результат. 
Формально, оценка $\hat{\theta}$ считается несмещенной, если:
$E[\hat{\theta}] = \theta$ 
где $E[\hat{\theta}]$ — это математическое ожидание оценки $\hat{\theta}$, а $\theta$ — истинное значение параметра.
### 76. Ф-я правдоподобия (для непрерывных случайных величин)
Пусть у нас есть выборка $X_1, X_2, \ldots, X_n$ из абсолютно непрерывной случайной величины с плотностью вероятности $f(x; \theta)$, где $\theta$ — это параметр (или вектор параметров), который мы хотим оценить. 
Функция правдоподобия $\Phi(\theta)$ для данной выборки определяется как произведение плотностей вероятности для всех наблюдений: $\Phi(\theta) = f(X_1; \theta) \cdot f(X_2; \theta) \cdots f(X_n; \theta) = \prod_{i=1}^{n} f(X_i; \theta)$
### 77. Как определяется оценка максимального правдоподобия через ф-ю правдоподобия
Для нахождения оценки максимального правдоподобия (MLE) параметра $\theta$ мы ищем такое значение $\hat{\theta}$, которое максимизирует функцию правдоподобия $L(\theta)$ 
$\hat{\theta} = \arg \max_{\theta} L(\theta)$
### 78. Ф-я правдоподобия и логарифмическая ф-я правдоподобия для распределения Бернулли
Параметром, который мы оцениваем, является $p$
Для набора независимых наблюдений $X_1,X_2,…,X_n$, где каждое $X_i$ имеет распределение Бернулли с параметром $p$, функция правдоподобия $\Phi(p)$ для $n$ наблюдений будет:
$\Phi(p) = \prod_{i=1}^{n}P(X_i = x_i) = \prod_{i=1}^{n}p^{x_i}(1-p)^{1-x_i}$
Логарифмическая для распределения Бернулли:
$L(p) = \sum_{i=1}^{n}(x_i \cdot ln(p) + (1-x_i) \cdot ln(1-p))$
### 79. Байесовская постановка задачи оценки параметра: что такое априорное и апостериорное распределения
**Априорное распределение** $P(\theta)$:
Это распределение, которое отражает наши предварительные знания или предположения о параметре $\theta$ до получения данных. Априорное распределение может быть выбрано на основе предыдущих исследований, экспертных оценок или других источников информации. Например, если мы предполагаем, что параметр $\theta$ может принимать значения в диапазоне от 0 до 1, мы можем использовать бета-распределение в качестве априорного распределения.
**Апостериорное распределение** $P(\theta | X)$: 
Это распределение, которое отражает наши обновленные знания о параметре $\theta$ после получения данных $X$. Апостериорное распределение вычисляется с использованием теоремы Байеса:
$P(\theta | X) = \frac{P(X | \theta) P(\theta)}{P(X)}$ 
где $P(X)$ — это нормализующий коэффициент, который обеспечивает, что интеграл апостериорного распределения по всем возможным значениям $\theta$ равен 1. Он может быть вычислен как: 
$P(X) = \int P(X | \theta) P(\theta) d\theta$
### 80. Сопряженное априорное распределение
Если апостериорное распределение принадлежит тому же семейству распределений, что и априорное (т.е. имеет тот же вид, но с другими параметрами), то априорное распределение называют сопряженным.
### 81. Бета распределение: его ядро, плотность, матожидание и дисперсия
**Бе́та-распределе́ние** в теории вероятностей и статистике — двухпараметрическое семейство абсолютно непрерывных распределений. Используется для описания случайных величин, значения которых ограничены конечным интервалом.
Плотность вероятности:
$f_X(x) = \frac{1}{B(\alpha, \beta)}x^{\alpha-1}(1-x)^{\beta-1}$, при этом $x \in [0,1]$
где $B(\alpha, \beta) = \int_{0}^{1}x^{\alpha-1}(1-x)^{\beta-1}dx$ - бета-функция.
Так же бета-функцию можно выразить через гамма-функции: $B(\alpha, \beta) = \frac{\Gamma(\alpha) \cdot \Gamma(\beta)}{\Gamma(\alpha + \beta)}$
Тогда плотность будет выглядеть следующим образом:
$f_X(x) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha) \cdot \Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}$
Ядро:
$x^{\alpha-1}(1-x)^{\beta-1}$, при этом $x \in [0,1]$
Матожидание и дисперсия:
$Ex = \frac{\alpha}{\alpha+\beta}$
$Dx = \frac{\alpha \cdot \beta}{(\alpha+\beta)^2 \cdot (\alpha + \beta + 1)}$
При $\alpha = \beta$:
$Ex = \frac{1}{2}$
$Dx = \frac{1}{4 \cdot (2\alpha + 1)}$
### 82. Некорректное априорное распределение
Априорное распределение, которое не является корректным вероятностным распределением, т.к. его интеграл по $R$ (плотность?) бесконечен или не существует.
Несмотря на это, однако, его можно использовать, если оно приводит к корректному апостериорному распределению.
### 83. Различия между простыми и сложными гипотезами
Любое предположение относительно параметров или закона распределения наблюдаемой случайной величины (или нескольких величин) называется _статистической гипотезой_. Проверяемую статистическую гипотезу также называют _основной_, или _нулевой_, статистической гипотезой и, как правило, обозначают $H_0$.

Наряду с проверяемой статистической гипотезой $H_0$ выдвигают также конкурирующую гипотезу, противоречащую $H_0$. Конкурирующая гипотеза называется _альтернативной_ и, как правило, обозначается $H_1$ или $H’$. Если в результате статистического анализа делается вывод, что основная гипотеза $H_0$ должна быть отвергнута, то решение принимается в пользу альтернативной гипотезы $H’$. В простейшем случае альтернативная гипотеза – это отрицание основной гипотезы.

Статистическая гипотеза $H_0$ называется **_простой_**, если она однозначно определяет параметр или распределение наблюдаемой случайной величины $X$. В противном случае гипотеза $H_0$ называется **_сложной_**. Т.е. гипотеза называется сложной, если мы не знаем распределения выборки и простой, если знаем.
### 84. Ошибки первого и второго рода (описать)
_Ошибкой 1-го рода_ при принятии статистического решения называется событие, состоящее в том, что основная гипотеза $H_0$ отвергается, в то время как она верна.
Соответственно вероятностью ошибки первого рода называют
$α_1 ∶= P_{H_0}(δ(X1, . . . , Xn) = 1)$.

_Ошибкой 2-го рода_ при принятии статистического решения называется событие, состоящее в том, что основная гипотеза $H_0$ принимается, в то время как верна альтернативная гипотеза $H_1$.
Соответственно вероятностью ошибки второго рода называют
$α_2 ∶= P_{H_1}(δ(X1, . . . , Xn) = 0)$.

Из определения выше видно, что **ошибки первого и второго рода** являются взаимно-симметричными, то есть если поменять местами гипотезы $H_0$ и $H_1$, то _ошибки первого рода_ превратятся в _ошибки второго рода_ и наоборот. Тем не менее, в большинстве практических ситуаций путаницы не происходит, поскольку принято считать, что _нулевая гипотеза_ H0 соответствует состоянию «по умолчанию» (естественному, наиболее ожидаемому положению вещей) — например, что обследуемый человек здоров, или что проходящий через рамку металлодетектора пассажир не имеет запрещённых металлических предметов. Соответственно, _альтернативная гипотеза_ $H_1$ обозначает противоположную ситуацию, которая обычно трактуется как менее вероятная, неординарная, требующая какой-либо реакции.

С учётом вышесказанного, _ошибку первого рода_ часто называют **ложной тревогой**, **ложным срабатыванием** или **ложноположительным срабатыванием**. Если, например, анализ крови показал наличие заболевания, хотя на самом деле человек здоров, или металлодетектор выдал сигнал тревоги, сработав на металлическую пряжку ремня, то принятая гипотеза не верна, а следовательно совершена ошибка первого рода. Слово «ложноположительный» в данном случае не имеет отношения к желательности или нежелательности самого события.
Проще говоря, ошибка первого рода - false positive

Соответственно, _ошибку второго рода_ иногда называют **пропуском события** или **ложноотрицательным срабатыванием**. Человек болен, но анализ крови этого не показал, или у пассажира имеется холодное оружие, но рамка металлодетектора его не обнаружила (например, из-за того, что чувствительность рамки отрегулирована на обнаружение только очень массивных металлических предметов). Данные примеры указывают на совершение ошибки второго рода. Слово «ложноотрицательный» в данном случае не имеет отношения к желательности или нежелательности самого события.
Её можно обозначить как false negative
### 85. Что такое статистика критерия
В итоге мы должны на основе выборки принять решение о том принимаем ли мы гипотезу $H_0$ или $H_1$.
Другими словами нам нужна функция $δ(X1, . . . , Xn)$, зависящая от выборки
и способная возвращать два значения, соответствующие нашим гипотезам.
Будем называть критерием любую функцию
$δ(X1, . . . , Xn) ∶ R^n → {0, 1}$.
Если $δ(X1, . . . , Xn) = 0$, то мы принимаем основную гипотезу $H_0$. Если же $δ(X1, . . . , Xn) = 1$, то мы отвергаем основную гипотезу и принимаем альтернативу $H_1$.
...
Статистика - измеримая числовая функция от выборки, не зависящая от неизвестных параметров распределения элементов выборки.

Для поверки гипотез используется функция, называемая статистикой критерия, которая зависит от выборки.
Статистикой критерия называется _случайная величина, значение которой вычисляется по выборке_.

Полагаю, что для лектора критерий = статистика критерия
### 86. p-значение
p-value - Вероятность получить для данной вероятностной модели распределения значений случайной величины такое же или более экстремальное значение статистики (среднего арифметического, медианы и др.), по сравнению с ранее наблюдаемым, при условии, что $H_0$ (нулевая гипотеза) верна.

Пусть $T(X)$ — статистика, используемая при тестировании некоторой нулевой гипотезы H0. Предполагается, что если нулевая гипотеза справедлива, то распределение этой статистики известно. Обозначим функцию распределения $F(t)=P(T<t)$. P-значение чаще всего (при проверке правосторонней альтернативы) определяется как:
$P(t)=P(T>t)=1−F(t)$
При проверке левосторонней альтернативы,
$P_0(t)=P(T<t)=F(t)$
В случае двустороннего теста p-значение равно:
$P(t)=2min(P_0,P)$
Если $p(t)$ меньше заданного уровня значимости, то нулевая гипотеза отвергается в пользу альтернативной. В противном случае она не отвергается.
Преимуществом данного подхода является то, что видно при каком уровне значимости нулевая гипотеза будет отвергнута, а при каких принята, то есть виден уровень надежности статистических выводов, точнее вероятность ошибки при отвержении нулевой гипотезы. При любом уровне значимости больше $p$ нулевая гипотеза отвергается, а при меньших значениях — нет.
### 87. Критическое множество
Критической областью (множеством) называется область значений статистики критерия, при которых отвергается $H_0$. А критические значения - это граница критической области (множества).
Существует три вида критических областей: левосторонняя, правосторонняя и двусторонняя. Вид критической области определяется видом альтернативной гипотезы:
Если $H_1 : \theta \neq \theta_0$, то критическое множество является двусторонним
Если $H_1 : \theta > \theta_0$, то критическое множество является правосторонним
Если $H_1 : \theta < \theta_0$, то критическое множество является левосторонним
Критическая область зависит от уровня значимости.
### 88. Уравнение линейной регрессии: известные и случайные переменные
Суть линейной регрессии - попытка описать наблюдаемую линейную зависимость $\{x_i\}_{i=1}^{n}$ и $\{y_i\}_{i=1}^{n}$ с линейной функцией зависимости

Дана выборка $x^n = \{(x_1,y_1), ..., (x_n, y_n);x_i,y_i \in R\}$
Уравнение: $y_i = b_0 + b_1x_i$ - простая линейная регрессия
$y_i$ - предсказание модели (отклик)
$b_0$ - константа/свободный член
$b_1$ - наклон/угловой коэффициент
$x_i$ - фактор/объясняющая переменная
### 89. Выборочная корреляция
Выборочная корреляция — это статистическая мера, которая оценивает степень и направление линейной зависимости между двумя переменными в выборке данных. Она позволяет понять, насколько сильно и в каком направлении изменяется одна переменная в зависимости от другой.
$$
r_{XY} = \frac{cov_{XY}}{\sigma_X\sigma_Y} = \frac{\sum_{i=1}^{n}(X - \overline{X})(Y - \overline{Y})}{\sqrt{\sum_{i=1}^{n}(X - \overline{X})^2\sum_{i=1}^{n}(Y-\overline{Y})^2}}
$$
где $\overline{X} = \frac{1}{n}\sum_{t=1}^{n}X_t$, $\overline{Y} = \frac{1}{n}\sum_{t=1}^{n}Y_t$ - среднее для выборок
1. Абсолютное значение корреляции измеряет силу линейной
связи между величинами;
2. Знак корреляции означает “направление” этой связи:
положительная корреляция означает что рост одного
параметра влечет рост другого, отрицательная - наоборот;
3. Коэффициент корреляции всегда лежит между –1 и 1,
означающими идеальную линейную связь. 0 означает
отсутствие линейной связи,
4. Коэффициент корреляции не зависит от смещения или
единиц измерения числовых величин, т.е. он не меняется
от линейного преобразования с положительным
множителем;
### 90. Оценки параметров парной регрессии
$b_1 = \frac{\sigma_y}{\sigma_x}r_{x,y}$
$b_0 = \overline{y}-b_1\overline{x}$
### 91. Что такое доля объясненной дисперсии и может ли она уменьшится при добавлении новой переменной в модель?
Объясненная дисперсия - это мера того, сколько из общей дисперсии в зависимой переменной объясняется независимыми переменными.
$R^2 = r_{x,y}^{2}$
Эта величина описывает долю вариации предсказываемой
величины y, которую описывает наша модель.
$0 \leq R^2 \leq 1$
- $R^2=0$: Модель не объясняет вариацию зависимой переменной.
- $R^2=1$: Модель полностью объясняет вариацию зависимой переменной.
- Значения между 0 и 1 указывают на степень объясненной дисперсии: чем ближе к 1, тем лучше модель объясняет данные.
При добавлении новой независимой переменной в модель $R^2$ **никогда не может уменьшиться**. Это связано с тем, что добавление переменной всегда может либо улучшить, либо оставить без изменений объясняемую дисперсию, но не ухудшить её.
### 92. Ф-я правдоподобия логистической регрессии
Для набора наблюдений $(Xi,Yi)$ для $i=1,2,…,n$ функция правдоподобия $L(β)$ может быть записана как произведение вероятностей для всех наблюдений:
$L(β)=∏_{i=1}^{n}​P(Yi​|Xi​)=∏_{i=1}^{n}​σ(β^TX_i​)^{Y_i}​(1−σ(β^TX_i​))^{1−Y_i}​$
где:
- $Yi$ — значение зависимой переменной для ii-го наблюдения,
- $P(Yi∣Xi)$ — вероятность наблюдения YiYi​ при заданном XiXi​.
